{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba143904",
   "metadata": {},
   "source": [
    "# 1. Data Extraction via API (2021 - 2023) \n",
    "Note: Following script does not use hopworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50fd11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp           update_timestamp  west  east  central  \\\n",
      "0      2021-11-30T00:00:00  2021-11-30T00:08:52+08:00   5.0  12.0     14.0   \n",
      "1      2021-11-30T01:00:00  2021-11-30T01:08:52+08:00   8.0  14.0     12.0   \n",
      "2      2021-11-30T02:00:00  2021-11-30T02:08:52+08:00   9.0  17.0     14.0   \n",
      "3      2021-11-30T03:00:00  2021-11-30T03:08:52+08:00   6.0  14.0     18.0   \n",
      "4      2021-11-30T04:00:00  2021-11-30T04:08:52+08:00   6.0  14.0     17.0   \n",
      "...                    ...                        ...   ...   ...      ...   \n",
      "17540  2023-11-30T20:00:00  2023-11-30T20:03:53+08:00  14.0  10.0      9.0   \n",
      "17541  2023-11-30T21:00:00  2023-11-30T21:03:52+08:00   3.0   9.0      3.0   \n",
      "17542  2023-11-30T22:00:00  2023-11-30T22:03:53+08:00   5.0   9.0      8.0   \n",
      "17543  2023-11-30T23:00:00  2023-11-30T23:03:52+08:00   5.0   9.0      9.0   \n",
      "17544  2023-12-01T00:00:00  2023-12-01T00:03:52+08:00   4.0   5.0      5.0   \n",
      "\n",
      "       south  north  \n",
      "0        6.0   14.0  \n",
      "1        9.0   13.0  \n",
      "2       12.0   16.0  \n",
      "3        6.0   12.0  \n",
      "4        7.0   14.0  \n",
      "...      ...    ...  \n",
      "17540    8.0    5.0  \n",
      "17541    6.0    4.0  \n",
      "17542    4.0    4.0  \n",
      "17543   10.0    5.0  \n",
      "17544    6.0    6.0  \n",
      "\n",
      "[17545 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# API endpoint for retrieving PM2.5 information\n",
    "api_url = \"https://api.data.gov.sg/v1/environment/pm25\"\n",
    "\n",
    "# Define the start and end timestamps\n",
    "start_timestamp = datetime(2021, 11, 30, 0, 0, 0)  # Take 30th November 2021, 1200 as start date\n",
    "end_timestamp = datetime(2023, 12, 1, 0, 0, 0)    # Take 1st Dec 2023, 0000 as end date\n",
    "\n",
    "# Define the time interval (e.g., hourly)\n",
    "time_interval = timedelta(hours=1)            # Using 1 hourly interval\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "all_data = []\n",
    "\n",
    "# Make API requests for each timestamp in the specified range\n",
    "current_timestamp = start_timestamp\n",
    "while current_timestamp <= end_timestamp:\n",
    "    # Format the timestamp in the required format\n",
    "    formatted_timestamp = current_timestamp.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(api_url, params={\"date_time\": formatted_timestamp})\n",
    "\n",
    "    # Process the response (you can adapt this based on the actual API response format)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Assuming the API returns JSON\n",
    "        # Extract relevant information and append to the list\n",
    "        timestamp_data = {\n",
    "            \"timestamp\": formatted_timestamp,\n",
    "            \"update_timestamp\": data.get(\"items\", [])[0].get(\"update_timestamp\", \"\"),\n",
    "            \"pm25_readings\": data.get(\"items\", [])[0].get(\"readings\", {}).get(\"pm25_one_hourly\", {})\n",
    "        }\n",
    "        all_data.append(timestamp_data)\n",
    "    else:\n",
    "        print(f\"Error for timestamp {formatted_timestamp}: {response.status_code}, {response.text}\")\n",
    "\n",
    "    # Move to the next timestamp\n",
    "    current_timestamp += time_interval\n",
    "\n",
    "# Convert the accumulated data into a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Normalize the 'pm25_readings' column\n",
    "pm25_normalized = pd.json_normalize(df['pm25_readings'])\n",
    "\n",
    "# Concatenate the normalized columns with the original DataFrame\n",
    "df = pd.concat([df, pm25_normalized], axis=1)\n",
    "\n",
    "# Drop the original 'pm25_readings' column\n",
    "df = df.drop(['pm25_readings'], axis=1)\n",
    "\n",
    "# Optionally, you can drop unnecessary columns or reorder them\n",
    "df = df[['timestamp', 'update_timestamp', 'west', 'east', 'central', 'south', 'north']]\n",
    "\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('pm25_data_raw.csv', index=False)\n",
    "\n",
    "# Print or use the resulting DataFrame as needed\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e433b28",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53dba7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp           update_timestamp  west  east  central  \\\n",
      "0      2021-11-30T00:00:00  2021-11-30T00:08:52+08:00   5.0  12.0     14.0   \n",
      "1      2021-11-30T01:00:00  2021-11-30T01:08:52+08:00   8.0  14.0     12.0   \n",
      "2      2021-11-30T02:00:00  2021-11-30T02:08:52+08:00   9.0  17.0     14.0   \n",
      "3      2021-11-30T03:00:00  2021-11-30T03:08:52+08:00   6.0  14.0     18.0   \n",
      "4      2021-11-30T04:00:00  2021-11-30T04:08:52+08:00   6.0  14.0     17.0   \n",
      "...                    ...                        ...   ...   ...      ...   \n",
      "17540  2023-11-30T20:00:00  2023-11-30T20:03:53+08:00  14.0  10.0      9.0   \n",
      "17541  2023-11-30T21:00:00  2023-11-30T21:03:52+08:00   3.0   9.0      3.0   \n",
      "17542  2023-11-30T22:00:00  2023-11-30T22:03:53+08:00   5.0   9.0      8.0   \n",
      "17543  2023-11-30T23:00:00  2023-11-30T23:03:52+08:00   5.0   9.0      9.0   \n",
      "17544  2023-12-01T00:00:00  2023-12-01T00:03:52+08:00   4.0   5.0      5.0   \n",
      "\n",
      "       south  north  \n",
      "0        6.0   14.0  \n",
      "1        9.0   13.0  \n",
      "2       12.0   16.0  \n",
      "3        6.0   12.0  \n",
      "4        7.0   14.0  \n",
      "...      ...    ...  \n",
      "17540    8.0    5.0  \n",
      "17541    6.0    4.0  \n",
      "17542    4.0    4.0  \n",
      "17543   10.0    5.0  \n",
      "17544    6.0    6.0  \n",
      "\n",
      "[17545 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# To save time from reloading above API - load from previous csv file saved (if already loaded, you may skip this step)\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('pm25_data_raw.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31391e9",
   "metadata": {},
   "source": [
    "# Find missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47471843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>df_missing</th>\n",
       "      <th>df_missing_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>update_timestamp</td>\n",
       "      <td>418</td>\n",
       "      <td>2.382445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>west</td>\n",
       "      <td>418</td>\n",
       "      <td>2.382445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>east</td>\n",
       "      <td>418</td>\n",
       "      <td>2.382445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>central</td>\n",
       "      <td>418</td>\n",
       "      <td>2.382445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>south</td>\n",
       "      <td>418</td>\n",
       "      <td>2.382445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>north</td>\n",
       "      <td>418</td>\n",
       "      <td>2.382445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>timestamp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            columns  df_missing  df_missing_percentage\n",
       "0  update_timestamp         418               2.382445\n",
       "1              west         418               2.382445\n",
       "2              east         418               2.382445\n",
       "3           central         418               2.382445\n",
       "4             south         418               2.382445\n",
       "5             north         418               2.382445\n",
       "6         timestamp           0               0.000000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Count the missing values in df and test datasets\n",
    "df_missing = df.isnull().sum().sort_values(ascending=False)[:13].reset_index()\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "df_missing_percentage = (df_missing[0] / len(df)) * 100\n",
    "\n",
    "# Add columns for missing values and percentages\n",
    "df_missing['df_missing_percentage'] = df_missing_percentage\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_missing.columns = ['columns', 'df_missing', 'df_missing_percentage']\n",
    "\n",
    "df_missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1b55123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with any missing values:\n",
      "                 timestamp update_timestamp  west  east  central  south  north\n",
      "8384   2022-11-14T08:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "8385   2022-11-14T09:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "8386   2022-11-14T10:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "8387   2022-11-14T11:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "8388   2022-11-14T12:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "...                    ...              ...   ...   ...      ...    ...    ...\n",
      "16950  2023-11-06T06:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "16951  2023-11-06T07:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "16952  2023-11-06T08:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "16953  2023-11-06T09:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "16954  2023-11-06T10:00:00              NaN   NaN   NaN      NaN    NaN    NaN\n",
      "\n",
      "[418 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in df\n",
    "missing_values_df = df[df.isnull().any(axis=1)]\n",
    "\n",
    "# Print the DataFrame with rows containing missing values\n",
    "print(\"Rows with any missing values:\")\n",
    "print(missing_values_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb1cc93c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame without missing values:\n",
      "                 timestamp           update_timestamp  west  east  central  \\\n",
      "0      2021-11-30T00:00:00  2021-11-30T00:08:52+08:00   5.0  12.0     14.0   \n",
      "1      2021-11-30T01:00:00  2021-11-30T01:08:52+08:00   8.0  14.0     12.0   \n",
      "2      2021-11-30T02:00:00  2021-11-30T02:08:52+08:00   9.0  17.0     14.0   \n",
      "3      2021-11-30T03:00:00  2021-11-30T03:08:52+08:00   6.0  14.0     18.0   \n",
      "4      2021-11-30T04:00:00  2021-11-30T04:08:52+08:00   6.0  14.0     17.0   \n",
      "...                    ...                        ...   ...   ...      ...   \n",
      "17540  2023-11-30T20:00:00  2023-11-30T20:03:53+08:00  14.0  10.0      9.0   \n",
      "17541  2023-11-30T21:00:00  2023-11-30T21:03:52+08:00   3.0   9.0      3.0   \n",
      "17542  2023-11-30T22:00:00  2023-11-30T22:03:53+08:00   5.0   9.0      8.0   \n",
      "17543  2023-11-30T23:00:00  2023-11-30T23:03:52+08:00   5.0   9.0      9.0   \n",
      "17544  2023-12-01T00:00:00  2023-12-01T00:03:52+08:00   4.0   5.0      5.0   \n",
      "\n",
      "       south  north        date      time  year month day  \n",
      "0        6.0   14.0  2021-11-30  00:00:00  2021    11  30  \n",
      "1        9.0   13.0  2021-11-30  01:00:00  2021    11  30  \n",
      "2       12.0   16.0  2021-11-30  02:00:00  2021    11  30  \n",
      "3        6.0   12.0  2021-11-30  03:00:00  2021    11  30  \n",
      "4        7.0   14.0  2021-11-30  04:00:00  2021    11  30  \n",
      "...      ...    ...         ...       ...   ...   ...  ..  \n",
      "17540    8.0    5.0  2023-11-30  20:00:00  2023    11  30  \n",
      "17541    6.0    4.0  2023-11-30  21:00:00  2023    11  30  \n",
      "17542    4.0    4.0  2023-11-30  22:00:00  2023    11  30  \n",
      "17543   10.0    5.0  2023-11-30  23:00:00  2023    11  30  \n",
      "17544    6.0    6.0  2023-12-01  00:00:00  2023    12  01  \n",
      "\n",
      "[17127 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values from df\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Print the DataFrame without missing values\n",
    "print(\"DataFrame without missing values:\")\n",
    "print(df_without_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0fafd",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a41bd",
   "metadata": {},
   "source": [
    "# Feature Construction: timestamp - Date | Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2156e15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xueer\\AppData\\Local\\Temp\\ipykernel_26208\\3530707872.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[['date', 'time']] = df_cleaned['timestamp'].str.split('T', expand=True)\n",
      "C:\\Users\\xueer\\AppData\\Local\\Temp\\ipykernel_26208\\3530707872.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[['date', 'time']] = df_cleaned['timestamp'].str.split('T', expand=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>update_timestamp</th>\n",
       "      <th>west</th>\n",
       "      <th>east</th>\n",
       "      <th>central</th>\n",
       "      <th>south</th>\n",
       "      <th>north</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-30T00:00:00</td>\n",
       "      <td>2021-11-30T00:08:52+08:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-30T01:00:00</td>\n",
       "      <td>2021-11-30T01:08:52+08:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-30T02:00:00</td>\n",
       "      <td>2021-11-30T02:08:52+08:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-30T03:00:00</td>\n",
       "      <td>2021-11-30T03:08:52+08:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-30T04:00:00</td>\n",
       "      <td>2021-11-30T04:08:52+08:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17540</th>\n",
       "      <td>2023-11-30T20:00:00</td>\n",
       "      <td>2023-11-30T20:03:53+08:00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17541</th>\n",
       "      <td>2023-11-30T21:00:00</td>\n",
       "      <td>2023-11-30T21:03:52+08:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17542</th>\n",
       "      <td>2023-11-30T22:00:00</td>\n",
       "      <td>2023-11-30T22:03:53+08:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17543</th>\n",
       "      <td>2023-11-30T23:00:00</td>\n",
       "      <td>2023-11-30T23:03:52+08:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17544</th>\n",
       "      <td>2023-12-01T00:00:00</td>\n",
       "      <td>2023-12-01T00:03:52+08:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17127 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp           update_timestamp  west  east  central  \\\n",
       "0      2021-11-30T00:00:00  2021-11-30T00:08:52+08:00   5.0  12.0     14.0   \n",
       "1      2021-11-30T01:00:00  2021-11-30T01:08:52+08:00   8.0  14.0     12.0   \n",
       "2      2021-11-30T02:00:00  2021-11-30T02:08:52+08:00   9.0  17.0     14.0   \n",
       "3      2021-11-30T03:00:00  2021-11-30T03:08:52+08:00   6.0  14.0     18.0   \n",
       "4      2021-11-30T04:00:00  2021-11-30T04:08:52+08:00   6.0  14.0     17.0   \n",
       "...                    ...                        ...   ...   ...      ...   \n",
       "17540  2023-11-30T20:00:00  2023-11-30T20:03:53+08:00  14.0  10.0      9.0   \n",
       "17541  2023-11-30T21:00:00  2023-11-30T21:03:52+08:00   3.0   9.0      3.0   \n",
       "17542  2023-11-30T22:00:00  2023-11-30T22:03:53+08:00   5.0   9.0      8.0   \n",
       "17543  2023-11-30T23:00:00  2023-11-30T23:03:52+08:00   5.0   9.0      9.0   \n",
       "17544  2023-12-01T00:00:00  2023-12-01T00:03:52+08:00   4.0   5.0      5.0   \n",
       "\n",
       "       south  north        date      time  \n",
       "0        6.0   14.0  2021-11-30  00:00:00  \n",
       "1        9.0   13.0  2021-11-30  01:00:00  \n",
       "2       12.0   16.0  2021-11-30  02:00:00  \n",
       "3        6.0   12.0  2021-11-30  03:00:00  \n",
       "4        7.0   14.0  2021-11-30  04:00:00  \n",
       "...      ...    ...         ...       ...  \n",
       "17540    8.0    5.0  2023-11-30  20:00:00  \n",
       "17541    6.0    4.0  2023-11-30  21:00:00  \n",
       "17542    4.0    4.0  2023-11-30  22:00:00  \n",
       "17543   10.0    5.0  2023-11-30  23:00:00  \n",
       "17544    6.0    6.0  2023-12-01  00:00:00  \n",
       "\n",
       "[17127 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split 'timestamp' into 2 columns - Date | Time\n",
    "df_cleaned[['date', 'time']] = df_cleaned['timestamp'].str.split('T', expand=True)\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84c26ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xueer\\AppData\\Local\\Temp\\ipykernel_26208\\2012494841.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[['year','month','day']] = df_cleaned['date'].str.split('-', expand=True)\n",
      "C:\\Users\\xueer\\AppData\\Local\\Temp\\ipykernel_26208\\2012494841.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[['year','month','day']] = df_cleaned['date'].str.split('-', expand=True)\n",
      "C:\\Users\\xueer\\AppData\\Local\\Temp\\ipykernel_26208\\2012494841.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[['year','month','day']] = df_cleaned['date'].str.split('-', expand=True)\n"
     ]
    }
   ],
   "source": [
    "#Split 'date' into 3 columns - Year | Month | Day\n",
    "df_cleaned[['year','month','day']] = df_cleaned['date'].str.split('-', expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9023a4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xueer\\AppData\\Local\\Temp\\ipykernel_26208\\2347755829.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['hour'] = df_cleaned['time'].str[:2]\n"
     ]
    }
   ],
   "source": [
    "#split 'time' into only hour \n",
    "df_cleaned['hour'] = df_cleaned['time'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a41dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop timestamp and updated timestamp only keep necessary columns. \n",
    "df_cleaned = df_cleaned.drop(['timestamp', 'update_timestamp','date', 'time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3640139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>west</th>\n",
       "      <th>east</th>\n",
       "      <th>central</th>\n",
       "      <th>south</th>\n",
       "      <th>north</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   west  east  central  south  north  year month day hour\n",
       "0   5.0  12.0     14.0    6.0   14.0  2021    11  30   00\n",
       "1   8.0  14.0     12.0    9.0   13.0  2021    11  30   01\n",
       "2   9.0  17.0     14.0   12.0   16.0  2021    11  30   02\n",
       "3   6.0  14.0     18.0    6.0   12.0  2021    11  30   03\n",
       "4   6.0  14.0     17.0    7.0   14.0  2021    11  30   04"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "df_cleaned.to_csv('pm25_data_cleaned.csv', index=False)\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1167e6",
   "metadata": {},
   "source": [
    "# 4. Experiment with Different Models (before hyperparameter Tuning)\n",
    "A lower MSE indicates better model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6338e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbours Cross-Validation Mean Squared Error: 25.4519\n",
      "K-Nearest Neighbours Test Mean Squared Error: 22.9867\n",
      "\n",
      "SVR Cross-Validation Mean Squared Error: 40.8408\n",
      "SVR Test Mean Squared Error: 40.4865\n",
      "\n",
      "Linear Regression Cross-Validation Mean Squared Error: 47.3943\n",
      "Linear Regression Test Mean Squared Error: 47.3775\n",
      "\n",
      "XGBoost Cross-Validation Mean Squared Error: 21.0686\n",
      "XGBoost Test Mean Squared Error: 19.9004\n",
      "\n",
      "Random Forest Cross-Validation Mean Squared Error: 16.0689\n",
      "Random Forest Test Mean Squared Error: 14.1625\n",
      "\n",
      "AdaBoost Cross-Validation Mean Squared Error: 46.6465\n",
      "AdaBoost Test Mean Squared Error: 46.9082\n",
      "\n",
      "Bagging Cross-Validation Mean Squared Error: 17.6467\n",
      "Bagging Test Mean Squared Error: 15.4516\n",
      "\n",
      "Gradient Boosted Trees Cross-Validation Mean Squared Error: 33.2426\n",
      "Gradient Boosted Trees Test Mean Squared Error: 33.2620\n",
      "\n",
      "HistGradient Boosted Trees Cross-Validation Mean Squared Error: 23.9681\n",
      "HistGradient Boosted Trees Test Mean Squared Error: 23.6923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming your data is stored in a variable named 'df_cleaned'\n",
    "# Extract features and target variables\n",
    "X = df_cleaned.drop(columns=['west', 'east', 'central', 'south', 'north'])\n",
    "y = df_cleaned[['west', 'east', 'central', 'south', 'north']]\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'K-Nearest Neighbours': KNeighborsRegressor(),   \n",
    "    'SVR': SVR(),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'AdaBoost': AdaBoostRegressor(),\n",
    "    'Bagging': BaggingRegressor(),\n",
    "    'Gradient Boosted Trees': GradientBoostingRegressor(),\n",
    "    'HistGradient Boosted Trees': HistGradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Evaluate models using k-fold cross-validation and calculate mean squared errors (5-fold)\n",
    "for model_name, model in models.items():\n",
    "    # Wrap the model in MultiOutputRegressor for multi-output regression\n",
    "    multioutput_model = MultiOutputRegressor(model)\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    scores = cross_val_score(multioutput_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_mse = round(-scores.mean(), 4)  # Convert negative MSE to positive\n",
    "    \n",
    "    # Train the model\n",
    "    multioutput_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions on the test set\n",
    "    y_pred = multioutput_model.predict(X_test)\n",
    "    \n",
    "    # Test mean squared error\n",
    "    test_mse = round(mean_squared_error(y_test, y_pred), 4)\n",
    "    \n",
    "    # Print mean squared errors with 4 decimal places\n",
    "    print(f'{model_name} Cross-Validation Mean Squared Error: {mean_mse:.4f}')\n",
    "    print(f'{model_name} Test Mean Squared Error: {test_mse:.4f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2b48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
